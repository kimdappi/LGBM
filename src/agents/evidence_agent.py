"""Evidence Agent - CRAG + 2-Pass íƒ€ê²Ÿ ê²€ìƒ‰.

êµ¬ì„±:
  1. PubMed / ë‚´ë¶€ RAG ê²€ìƒ‰
  2. LLM ì„ìƒ ë¶„ì„ ë° ì¿¼ë¦¬ ìƒì„±
  3. í’ˆì§ˆ í‰ê°€ ë° LLM ê²€ì¦
  4. Evidence Agent 1ì°¨ (CRAG)
  5. Evidence Agent 2ì°¨ (ë¹„íŒ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰)
"""

from Bio import Entrez
from typing import Dict, List
from openai import OpenAI
import os
import json
import re

# PubMed ì„¤ì •
Entrez.email = os.getenv("PUBMED_EMAIL", "researcher@example.com")

# CRAG ì„ê³„ì¹˜
SIMILARITY_THRESHOLD = 0.7


# ---------------------------------------------------------------------------
# 1. PubMed / ë‚´ë¶€ RAG ê²€ìƒ‰
# ---------------------------------------------------------------------------

def search_pubmed(query: str, max_results: int = 5, use_mesh: bool = True) -> List[Dict]:
    """
    PubMedì—ì„œ M&M ëª©ì (ë¹„íŒ/í•´ê²°ì±…)ì— ë§ëŠ” ë…¼ë¬¸ ê²€ìƒ‰
    
    Args:
        query: ê²€ìƒ‰ ì§ˆì˜
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        use_mesh: MeSH term ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    try:
        # M&M ëª©ì : ì˜¤ë¥˜/í•©ë³‘ì¦/ì˜ˆë°©/í•´ê²°ì±… íŠ¹í™” í•„í„°
        if use_mesh:
            # ìš°ì„ ìˆœìœ„ 1: ê°€ì´ë“œë¼ì¸ + ì•ˆì „/ì˜¤ë¥˜/í•©ë³‘ì¦ í‚¤ì›Œë“œ
            # ìš°ì„ ìˆœìœ„ 2: Systematic review (ê·¼ê±° ìˆ˜ì¤€ ë†’ìŒ)
            # ìš°ì„ ìˆœìœ„ 3: Clinical trial (ì‹¤ì œ ì¦ê±°)
            search_query = f"({query}) AND (guideline[pt] OR systematic review[pt] OR meta-analysis[pt] OR clinical trial[pt])"
        else:
            search_query = query
        
        handle = Entrez.esearch(db="pubmed", term=search_query, retmax=max_results, sort="relevance")
        record = Entrez.read(handle)
        handle.close()
        
        # Fallback: MeSH í•„í„°ë¡œ ê²°ê³¼ ì—†ìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰ ì¬ì‹œë„
        if not record["IdList"] and use_mesh:
            print(f"  [PubMed] No results with filters, retrying without filters...")
            handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results, sort="relevance")
            record = Entrez.read(handle)
            handle.close()
        
        if not record["IdList"]:
            return []
        
        # ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°
        handle = Entrez.efetch(db="pubmed", id=record["IdList"], rettype="abstract", retmode="xml")
        articles = Entrez.read(handle)
        handle.close()
        
        results = []
        for article in articles.get("PubmedArticle", []):
            medline = article.get("MedlineCitation", {})
            article_data = medline.get("Article", {})
            
            results.append({
                "pmid": str(medline.get("PMID", "")),
                "title": article_data.get("ArticleTitle", ""),
                "abstract": article_data.get("Abstract", {}).get("AbstractText", [""])[0] if article_data.get("Abstract") else "",
                "source": "pubmed"
            })
        
        return results

    except Exception as e:
        print(f"PubMed search error: {e}")
        return []


def search_internal_rag(query: str, rag_retriever, top_k: int = 3) -> List[Dict]:
    """ë‚´ë¶€ RAGì—ì„œ ìœ ì‚¬ ì¼€ì´ìŠ¤ ê²€ìƒ‰"""
    try:
        if hasattr(rag_retriever, 'retrieve_with_patient'):
            cohort = rag_retriever.retrieve_with_patient({"clinical_text": query}, top_k=top_k)
            cases = cohort.get("similar_cases", [])
            return [{"content": c.get("text", ""), "score": c.get("similarity", 0), "source": "internal", "case_id": c.get("id")} for c in cases]
        else:
            results = rag_retriever.search(query, top_k=top_k)
            return [{"content": r["text"], "score": r["score"], "source": "internal"} for r in results]
    except Exception as e:
        print(f"Internal RAG search error: {e}")
        return []


# ---------------------------------------------------------------------------
# 2. LLM ì„ìƒ ë¶„ì„ ë° ì¿¼ë¦¬ ìƒì„±
# ---------------------------------------------------------------------------

def analyze_clinical_context_with_llm(patient: Dict, structured_chart: Dict = None) -> Dict:
    """
    ğŸ¯ LLMìœ¼ë¡œ ì„ìƒ ë§¥ë½ ë¶„ì„ ë° ê²€ìƒ‰ ì „ëµ ìƒì„±
    
    Returns:
        {
            "clinical_priorities": ["PE", "ACS", ...],  # ì˜ì‹¬ë˜ëŠ” ì§„ë‹¨ë“¤
            "key_findings": ["hypoxia", "chest pain", ...],  # ì£¼ìš” ì†Œê²¬
            "risk_factors": ["post-op", "immobilization", ...],  # ìœ„í—˜ ì¸ì
            "search_strategy": str,  # ê²€ìƒ‰ ì „ëµ ì„¤ëª…
            "urgency_level": "critical/high/moderate/low"
        }
    """
    diagnosis = patient.get("diagnosis", "Unknown")
    
    # ê¸°ë³¸ ê²°ê³¼ ì¤€ë¹„
    default_result = {
        "clinical_priorities": [diagnosis],
        "key_findings": ["diagnosis confirmed"],
        "risk_factors": [],
        "urgency_level": "moderate",
        "search_strategy": "Evidence-based guideline search",
        "reasoning": "Basic analysis based on primary diagnosis"
    }
    
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        clinical_text = (patient.get("clinical_text", "") or patient.get("text", ""))[:2000]
        
        # Structured chart ì •ë³´ ì¶”ê°€
        vitals_info = ""
        if structured_chart:
            vitals = structured_chart.get('vitals', {})
            if vitals:
                vitals_info = f"\n\nVital Signs:\n{json.dumps(vitals, indent=2)}"
        
        prompt = f"""You analyze a clinical case to guide evidence search for M&M critique/solutions.

Primary diagnosis: {diagnosis}

Clinical text (may be truncated):
{clinical_text}{vitals_info}

Return ONLY valid JSON:
{{
  "clinical_priorities": ["life-threatening disease/complication", "â€¦", "â€¦"],
  "key_findings": ["key symptom/vital/lab", "..."],
  "risk_factors": ["risk factor/context", "..."],
  "urgency_level": "critical|high|moderate|low",
  "search_strategy": "what evidence is needed (errors/complications/prevention)",
  "reasoning": "one sentence"
}}

Rules:
- Priorities must be DISEASES/complications (e.g., PE/ACS/sepsis), not symptoms.
- Prefer commonly missed diagnoses and time-sensitive conditions."""

        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            max_tokens=1000,
            temperature=0,
            messages=[{"role": "user", "content": prompt}],
            timeout=30
        )
        
        # JSON íŒŒì‹±
        response_text = response.choices[0].message.content.strip()
        response_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
        
        result = json.loads(response_text)
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["clinical_priorities", "key_findings", "risk_factors", "urgency_level", "search_strategy"]
        for field in required_fields:
            if field not in result:
                print(f"  [Warning] Missing field '{field}', using default")
                result[field] = default_result[field]
        
        print(f"  [LLM Analysis] Priorities: {result.get('clinical_priorities', [])}")
        print(f"  [LLM Analysis] Urgency: {result.get('urgency_level', 'unknown')}")
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"  [ERROR] JSON parsing failed: {e}")
        print(f"  [Strategy] Using default clinical analysis")
        return default_result
    except Exception as e:
        print(f"  [ERROR] LLM clinical analysis failed: {e}")
        print(f"  [Strategy] Using default clinical analysis")
        return default_result


def generate_search_query_with_llm(patient: Dict, clinical_analysis: Dict = None) -> str:
    """
    ğŸ¯ LLMìœ¼ë¡œ ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    
    Args:
        patient: í™˜ì ì •ë³´
        clinical_analysis: analyze_clinical_context_with_llm() ê²°ê³¼
    
    Returns:
        str: ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ (ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¿¼ë¦¬)
    """
    diagnosis = patient.get("diagnosis", "Unknown")
    
    # ê¸°ë³¸ ì¿¼ë¦¬ ì¤€ë¹„ (LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    default_query = f"{diagnosis} complications diagnostic error"
    
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Clinical analysis ì •ë³´ í¬í•¨
        analysis_info = ""
        if clinical_analysis:
            priorities = clinical_analysis.get("clinical_priorities", [])
            findings = clinical_analysis.get("key_findings", [])
            risk_factors = clinical_analysis.get("risk_factors", [])
            
            analysis_info = f"""
Clinical Analysis:
- Differential diagnoses: {', '.join(priorities[:3])}
- Key findings: {', '.join(findings[:5])}
- Risk factors: {', '.join(risk_factors[:3])}
"""
        
        prompt = f"""Generate ONE short search query for similar cases/solutions (M&M purpose).

Primary diagnosis (must be first): {diagnosis}
{analysis_info}

Goal: Find similar cases or solutions about the Primary Diagnosis with diagnostic errors, complications, or important lessons.

Return ONLY the query string (no quotes, no explanation)."""

        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            max_tokens=100,
            temperature=0,
            messages=[{"role": "user", "content": prompt}],
            timeout=30
        )
        
        query = response.choices[0].message.content.strip().strip('"').strip("'")
        
        # ë¹ˆ ì¿¼ë¦¬ ë°©ì§€
        if not query or len(query.strip()) == 0:
            print(f"  [LLM Query] Empty result, using default query")
            return default_query
        
        print(f"  [LLM Query] Generated: {query}")
        return query
        
    except Exception as e:
        print(f"  [ERROR] LLM query generation failed: {e}")
        print(f"  [Strategy] Using default query: {default_query}")
        return default_query


def generate_pubmed_query_with_llm(patient: Dict, clinical_analysis: Dict = None) -> str:
    """
    ğŸ¯ LLMìœ¼ë¡œ PubMed ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    
    PubMedëŠ” max_results=5ë§Œ ê°€ì ¸ì˜¤ë¯€ë¡œ ë” êµ¬ì²´ì ì¼ìˆ˜ë¡ ì¢‹ìŒ
    
    Returns:
        str: ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ (ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¿¼ë¦¬)
    """
    diagnosis = patient.get("diagnosis", "Unknown")
    
    # ê¸°ë³¸ ì¿¼ë¦¬ ì¤€ë¹„ (LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    default_query = f"{diagnosis} complication prevention guideline"
    
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        secondary = patient.get("secondary_diagnoses", [])
        key_conditions = patient.get("key_conditions", [])
        
        # Clinical analysis ì •ë³´
        analysis_info = ""
        if clinical_analysis:
            priorities = clinical_analysis.get("clinical_priorities", [])
            risk_factors = clinical_analysis.get("risk_factors", [])
            
            analysis_info = f"""
Clinical Priorities: {', '.join(priorities[:3])}
Risk Factors: {', '.join(risk_factors[:3])}
"""
        
        comorbidities_info = ""
        if secondary or key_conditions:
            all_conditions = secondary + key_conditions
            comorbidities_info = f"\nComorbidities: {', '.join(all_conditions[:5])}"
        
        prompt = f"""Generate ONE PubMed query for M&M (errors/complications + prevention).

Primary Diagnosis: {diagnosis}
{comorbidities_info}
{analysis_info}

M&M Conference Goal:
- Find literature about ERRORS, COMPLICATIONS, and SOLUTIONS about the Primary Diagnosis
- Focus on what went wrong, what to avoid, and how to prevent
- NOT just general treatment guidelines

Context:
- PubMed will return only TOP 5 results (max_results=5)
- More specific = higher quality top 5
- Focus on: diagnostic errors, complications, adverse events, prevention strategies

Requirements:
1. 5-8 keywords total (specific but not too narrow)
2. PRIORITY ORDER (most important first):
   a) PRIMARY DIAGNOSIS (required, must be FIRST keyword)
   b) M&M keyword (diagnostic error / missed diagnosis / complication / prevention)
   c) Clinical context (post-operative, ICU, emergency, etc.)
   d) Risk factors or comorbidities (if relevant)
   e) "guideline" or "management" (optional, at the end)

Generate the query. Return ONLY the query string, no explanations."""

        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            max_tokens=100,
            temperature=0,
            messages=[{"role": "user", "content": prompt}],
            timeout=30
        )
        
        query = response.choices[0].message.content.strip().strip('"').strip("'")
        
        # ë¹ˆ ì¿¼ë¦¬ ë°©ì§€
        if not query or len(query.strip()) == 0:
            print(f"  [LLM PubMed Query] Empty result, using default query")
            return default_query
        
        print(f"  [LLM PubMed Query] Generated: {query}")
        return query
        
    except Exception as e:
        print(f"  [ERROR] LLM PubMed query generation failed: {e}")
        print(f"  [Strategy] Using default query: {default_query}")
        return default_query


# ---------------------------------------------------------------------------
# 3. í’ˆì§ˆ í‰ê°€ ë° LLM ê²€ì¦
# ---------------------------------------------------------------------------

def evaluate_internal_quality(internal_results: List[Dict], threshold: float = SIMILARITY_THRESHOLD) -> Dict:
    """
    ë‚´ë¶€ ê·¼ê±° í’ˆì§ˆ í‰ê°€ (í•„í„°ë§ í›„)
    
    Returns:
        {
            "is_sufficient": bool,
            "count": int,
            "avg_score": float,
            "reason": str
        }
    """
    if not internal_results:
        return {
            "is_sufficient": False,
            "count": 0,
            "avg_score": 0.0,
            "reason": "ìœ ì‚¬ ì¼€ì´ìŠ¤ ì—†ìŒ (ëª¨ë‘ ìœ ì‚¬ë„ < 0.7)"
        }
    
    scores = [r.get("score", 0) for r in internal_results]
    avg_score = sum(scores) / len(scores)
    
    # ì¶©ë¶„ ì¡°ê±´: ìµœì†Œ 1ê°œ ì´ìƒì˜ ìœ ì‚¬ ì¼€ì´ìŠ¤ (ì´ë¯¸ threshold í•„í„°ë§ í†µê³¼)
    is_sufficient = len(internal_results) >= 1
    
    return {
        "is_sufficient": is_sufficient,
        "count": len(internal_results),
        "avg_score": round(avg_score, 3),
        "reason": f"{len(internal_results)}ê±´ (í‰ê·  ìœ ì‚¬ë„: {avg_score:.3f})"
    }


def extract_key_events(text: str) -> Dict:
    """ì¼€ì´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ M&Mì— ì¤‘ìš”í•œ í•µì‹¬ ì´ë²¤íŠ¸ ì¶”ì¶œ"""
    default_events = {"outcome": None, "procedures": [], "complications": [], "critical_events": []}
    
    # None, ë¹ˆ ë¬¸ìì—´, ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    if not text or not isinstance(text, str) or not text.strip():
        return default_events
    
    text_lower = text.lower()
    events = {"outcome": None, "procedures": [], "complications": [], "critical_events": []}
    
    # Outcome ì¶”ì¶œ (ë‹¤ì–‘í•œ í‘œí˜„ ì§€ì›)
    death_keywords = [
        "expired", "died", "death", "deceased", "passed away",
        "discharge disposition:\nexpired", "discharge disposition: expired",
        "discharge location:\ndied", "discharge location: died",
        "cmo", "comfort measures", "withdrawal of care", "dnr/dni"
    ]
    survival_keywords = ["discharged home", "discharge to", "discharged to"]
    
    if any(kw in text_lower for kw in death_keywords):
        events["outcome"] = "death"
    elif any(kw in text_lower for kw in survival_keywords):
        events["outcome"] = "survived"
    elif "discharge" in text_lower:
        events["outcome"] = "survived"
    
    # ì‹œìˆ /í”„ë¡œì‹œì € ì¶”ì¶œ (í™•ì¥ëœ í‚¤ì›Œë“œ)
    procedure_keywords = [
        "paracentesis", "thoracentesis", "intubation", "intubated", "extubated",
        "egd", "endoscopy", "colonoscopy", "ercp", "tips", "bronchoscopy",
        "catheterization", "cardiac cath", "pci", "cabg", "surgery", "operation",
        "transfusion", "mtp", "massive transfusion", "prbc", "ffp", "platelets",
        "dialysis", "crrt", "hemodialysis", "central line", "a-line",
        "ct scan", "ctpa", "mri", "ultrasound", "biopsy", "lumbar puncture"
    ]
    for kw in procedure_keywords:
        if kw in text_lower and kw not in events["procedures"]:
            events["procedures"].append(kw)
    
    # í•©ë³‘ì¦/critical event ì¶”ì¶œ (í™•ì¥ëœ í‚¤ì›Œë“œ)
    complication_keywords = [
        "hemorrhage", "bleeding", "hemoperitoneum", "hematemesis", "melena", "hematochezia",
        "hypotension", "shock", "cardiac arrest", "code blue", "pulseless",
        "respiratory failure", "hypoxia", "hypoxemia", "ards", "respiratory distress",
        "renal failure", "aki", "acute kidney injury", "anuria", "oliguria",
        "hepatorenal", "encephalopathy", "altered mental status", "ams", "confusion",
        "sepsis", "septic shock", "bacteremia", "infection",
        "iatrogenic", "complication", "adverse event", "error",
        "hct drop", "hgb drop", "anemia", "coagulopathy", "dic",
        "pressors", "vasopressors", "norepinephrine", "vasopressin",
        "aspiration", "pneumonia", "pulmonary embolism", "pe", "dvt",
        "stroke", "mi", "myocardial infarction", "arrhythmia"
    ]
    for kw in complication_keywords:
        if kw in text_lower and kw not in events["complications"]:
            events["complications"].append(kw)
    
    # Critical ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ íŒ¨í„´ (í™•ì¥)
    critical_patterns = [
        # Procedure â†’ Complication
        (["paracentesis"], ["bleeding", "hemorrhage", "hemoperitoneum"], "paracentesis â†’ bleeding"),
        (["thoracentesis"], ["bleeding", "pneumothorax"], "thoracentesis â†’ complication"),
        (["central line", "catheter"], ["infection", "sepsis", "bacteremia"], "line â†’ infection"),
        (["surgery", "operation"], ["bleeding", "hemorrhage"], "surgery â†’ bleeding"),
        (["intubation"], ["aspiration", "pneumonia"], "intubation â†’ aspiration"),
        
        # Drug â†’ Adverse event
        (["lorazepam", "benzodiazepine", "ativan", "midazolam"], ["encephalopathy", "confusion", "ams"], "sedative â†’ HE worsening"),
        (["nsaid", "ketorolac", "ibuprofen"], ["renal failure", "aki", "creatinine"], "NSAID â†’ AKI"),
        (["anticoagulant", "heparin", "warfarin"], ["bleeding", "hemorrhage"], "anticoagulation â†’ bleeding"),
        
        # Cascade
        (["transfusion", "mtp", "prbc"], ["expired", "died", "death"], "transfusion â†’ death"),
        (["pressors", "vasopressor", "norepinephrine"], ["expired", "died", "death"], "vasopressors â†’ death"),
        (["intubation"], ["expired", "died", "death"], "intubation â†’ death"),
        
        # Disease progression
        (["cirrhosis"], ["hepatorenal", "hrs"], "cirrhosis â†’ HRS"),
        (["cirrhosis"], ["encephalopathy"], "cirrhosis â†’ HE"),
        (["sepsis"], ["shock", "hypotension"], "sepsis â†’ shock"),
    ]
    
    for triggers, outcomes, event_name in critical_patterns:
        if any(t in text_lower for t in triggers) and any(o in text_lower for o in outcomes):
            if event_name not in events["critical_events"]:
                events["critical_events"].append(event_name)
    
    return events


def validate_internal_evidence_with_llm(internal_results: List[Dict], patient: Dict) -> Dict:
    """
    LLMìœ¼ë¡œ ë‚´ë¶€ ê·¼ê±° ê²€ì¦ (M&M ë¹„íŒ/í•´ê²°ì— ìœ ìš©í•œì§€)
    
    ê°œì„ ì‚¬í•­:
    - ì¼€ì´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì´ë²¤íŠ¸(outcome, procedures, complications) ì¶”ì¶œ
    - í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ëŒ€ (300 â†’ 1000)
    - ìœ ì‚¬í•œ ê²°ê³¼/ê²½ê³¼ë„ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ì¸ì •
    """
    if not internal_results:
        return {
            "is_valid": False,
            "reason": "ë‚´ë¶€ ê·¼ê±° ì—†ìŒ",
            "confidence": 0.0,
            "filtered_results": []
        }
    
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ì¸ë±ìŠ¤ ì¼€ì´ìŠ¤ í•µì‹¬ ì´ë²¤íŠ¸ ì¶”ì¶œ
        index_text = patient.get('clinical_text', '') or patient.get('text', '')
        index_events = extract_key_events(index_text)
        
        # ë‚´ë¶€ ì¼€ì´ìŠ¤ ìš”ì•½ (í•µì‹¬ ì´ë²¤íŠ¸ í¬í•¨)
        cases_summary = []
        for i, case in enumerate(internal_results[:3]):
            content = case.get('content', '') or case.get('text', '')
            case_events = extract_key_events(content)
            
            # ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ (300 â†’ 1000)
            summary = f"""Case {i+1}:
- Outcome: {case_events['outcome'] or 'unknown'}
- Procedures: {', '.join(case_events['procedures'][:5]) or 'none'}
- Complications: {', '.join(case_events['complications'][:5]) or 'none'}
- Critical sequence: {', '.join(case_events['critical_events']) or 'none'}
- Text excerpt: {content[:1000]}..."""
            cases_summary.append(summary)
        
        prompt = f"""You judge whether retrieved cases are useful for M&M (Morbidity & Mortality) critique.

INDEX CASE (the patient being reviewed):
- Diagnosis: {patient.get('diagnosis', 'Unknown')}
- Outcome: {index_events['outcome'] or 'unknown'}
- Procedures: {', '.join(index_events['procedures'][:5]) or 'none'}
- Complications: {', '.join(index_events['complications'][:5]) or 'none'}
- Critical events: {', '.join(index_events['critical_events']) or 'none'}

CANDIDATE SIMILAR CASES:
{chr(10).join(cases_summary)}

VALIDATION CRITERIA - Mark is_valid=TRUE if ANY of the following:
1. SIMILAR OUTCOME: Same or related death/complication pathway (e.g., both died after procedure)
2. SIMILAR PROCEDURE + COMPLICATION: Same procedure with complications (e.g., paracentesis â†’ bleeding)
3. SIMILAR DISEASE TRAJECTORY: Same disease progression (e.g., cirrhosis â†’ HE â†’ death)
4. LEARNING VALUE: Case shows what went wrong or how to prevent similar outcomes

CRITICAL: A case with "paracentesis â†’ bleeding â†’ MTP â†’ death" is HIGHLY RELEVANT to another case with same trajectory. Do NOT reject just because the exact error keywords are missing.

Return JSON:
{{
  "is_valid": true/false,
  "reason": "one sentence explaining why useful or not for M&M learning",
  "valid_case_indices": [0,1,2],
  "confidence": 0.0-1.0
}}

Be GENEROUS with is_valid=true if the outcome/complication pattern matches."""

        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_object"},
            timeout=30
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        is_valid = result.get("is_valid", False)
        confidence = result.get("confidence", 0.0)
        reason = result.get("reason", "No reason provided")
        valid_indices = result.get("valid_case_indices", [])
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
        filtered_results = [internal_results[i] for i in valid_indices if i < len(internal_results)]
        
        # confidenceê°€ 0.5 ë¯¸ë§Œì´ë©´ is_validë¥¼ Falseë¡œ
        if confidence < 0.5:
            is_valid = False
        
        print(f"  [LLM Validation] is_valid={is_valid}, confidence={confidence:.2f}, reason={reason[:80]}...")
        
        return {
            "is_valid": is_valid,
            "reason": reason,
            "confidence": confidence,
            "filtered_results": filtered_results if is_valid else []
        }
        
    except json.JSONDecodeError as e:
        print(f"  [ERROR] LLM Validation JSON parsing failed: {e}")
        return {
            "is_valid": False,
            "reason": "Validation JSON parsing failed",
            "confidence": 0.0,
            "filtered_results": []
        }
    except Exception as e:
        print(f"  [ERROR] LLM Validation failed: {e}")
        return {
            "is_valid": False,
            "reason": f"Validation error: {str(e)}",
            "confidence": 0.0,
            "filtered_results": []
        }


# ---------------------------------------------------------------------------
# 3.5 Evidence í¬ë§·íŒ… (ê³µìœ  í•¨ìˆ˜ - Diagnosis/Treatment/Critic ê³µìš©)
# ---------------------------------------------------------------------------

def format_evidence_summary(evidence: Dict, include_abstract: bool = True) -> str:
    """
    Evidence ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ….
    Diagnosis/Treatment/Critic ë“± ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ .

    Args:
        evidence: run_evidence_agent() ë°˜í™˜ dict ì „ì²´
        include_abstract: PubMed abstract í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    if not evidence:
        return "ê²€ìƒ‰ëœ ê·¼ê±° ì—†ìŒ"

    lines: List[str] = []

    internal = evidence.get("internal", {})
    external = evidence.get("external", {})

    internal_results = internal.get("results", [])
    external_results = external.get("results", [])

    # â”€â”€ ë‚´ë¶€ ìœ ì‚¬ ì¼€ì´ìŠ¤ â”€â”€
    if internal_results:
        lines.append("### ë‚´ë¶€ ìœ ì‚¬ ì¼€ì´ìŠ¤")
        survived = [c for c in internal_results if str(c.get("status", "")).lower() in ("alive", "survived")]
        died = [c for c in internal_results if str(c.get("status", "")).lower() in ("dead", "died")]
        lines.append(f"- ìƒì¡´: {len(survived)}ê±´, ì‚¬ë§: {len(died)}ê±´")
        for c in internal_results[:3]:
            score = c.get("score", c.get("similarity", 0))
            status = c.get("status", "unknown")
            content = c.get("content", c.get("text", ""))
            lines.append(f"- [ìœ ì‚¬ë„ {score:.2f}] [{status}] {content}...")
    else:
        lines.append("### ë‚´ë¶€ ìœ ì‚¬ ì¼€ì´ìŠ¤: ì—†ìŒ (ìœ ì‚¬ë„ < 0.7)")

    # â”€â”€ PubMed ë¬¸í—Œ â”€â”€
    if external_results:
        lines.append("\n### ì™¸ë¶€ ë¬¸í—Œ (PubMed)")
        for e in external_results[:5]:
            lines.append(f"- [PMID: {e.get('pmid')}] {e.get('title', '')}")
            if include_abstract and e.get("abstract"):
                lines.append(f"  Abstract: {str(e['abstract'])}...")
    else:
        lines.append("\n### ì™¸ë¶€ ë¬¸í—Œ: ì—†ìŒ")

    # â”€â”€ 2ì°¨ ë¹„íŒ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰ ê²°ê³¼ â”€â”€
    critique_based = evidence.get("critique_based", {})
    critique_ext = critique_based.get("results", [])
    critique_int = critique_based.get("internal_results", [])
    if critique_ext or critique_int:
        lines.append("\n### ë¹„íŒ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰ (2ì°¨)")
        lines.append(f"ì¿¼ë¦¬: {critique_based.get('query', 'N/A')}")
        if critique_int:
            lines.append(f"  2ì°¨ ë‚´ë¶€ ìœ ì‚¬ ì¼€ì´ìŠ¤: {len(critique_int)}ê±´")
            for c in critique_int[:2]:
                score = c.get("score", 0)
                content = c.get("content", c.get("text", ""))
                lines.append(f"  - [ìœ ì‚¬ë„ {score:.2f}] {content}...")
        for e in critique_ext[:3]:
            lines.append(f"- [PMID: {e.get('pmid')}] {e.get('title', '')}")
            if include_abstract and e.get("abstract"):
                lines.append(f"  Abstract: {str(e['abstract'])}...")

    return "\n".join(lines)


def format_clinical_analysis(evidence: Dict) -> str:
    """
    Evidence Agentì˜ LLM ì„ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ….
    """
    if not evidence:
        return "ì„ìƒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

    analysis = evidence.get("clinical_analysis", {})
    if not analysis:
        return "ì„ìƒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

    lines: List[str] = []

    priorities = analysis.get("clinical_priorities", [])
    if priorities:
        lines.append(f"ì„ìƒ ìš°ì„ ìˆœìœ„: {', '.join(str(p) for p in priorities[:5])}")

    findings = analysis.get("key_findings", [])
    if findings:
        lines.append(f"ì£¼ìš” ì†Œê²¬: {', '.join(str(f) for f in findings[:5])}")

    risk_factors = analysis.get("risk_factors", [])
    if risk_factors:
        lines.append(f"ìœ„í—˜ ì¸ì: {', '.join(str(r) for r in risk_factors[:5])}")

    urgency = analysis.get("urgency_level", "")
    if urgency:
        lines.append(f"ê¸´ê¸‰ë„: {urgency}")

    strategy = analysis.get("search_strategy", "")
    if strategy:
        lines.append(f"ê²€ìƒ‰ ì „ëµ: {strategy}")

    return "\n".join(lines) if lines else "ì„ìƒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ"


# ---------------------------------------------------------------------------
# 4. Evidence Agent 1ì°¨ (CRAG: ìœ ì‚¬ ì¼€ì´ìŠ¤ + PubMed)
# ---------------------------------------------------------------------------

def run_evidence_agent(
    state: Dict,
    rag_retriever=None,
    similarity_threshold: float = SIMILARITY_THRESHOLD
) -> Dict:
    """
    Evidence Agent ì‹¤í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦ ê¸°ë°˜ CRAG)
    
    í•µì‹¬ ì „ëµ:
    1. ë‚´ë¶€ RAG ê²€ìƒ‰ (ìœ ì‚¬ë„ >= 0.7 í•„í„°ë§)
    2. í’ˆì§ˆ í‰ê°€: ìœ íš¨ ì¼€ì´ìŠ¤ >= 1ê°œ?
       - NO (0ê°œ) â†’ ì™¸ë¶€(PubMed)ë§Œ ì‚¬ìš©
       - YES (1ê°œ ì´ìƒ) â†’ LLM ê²€ì¦ ì§„í–‰
    3. LLM ê²€ì¦: ì‹¤ì œë¡œ ìœ ì‚¬í•˜ê³  ë¹„íŒ/í•´ê²°ì— ìœ ìš©í•œê°€?
       - í†µê³¼ â†’ ë‚´ë¶€ + ì™¸ë¶€ ëª¨ë‘ ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ)
       - ì‹¤íŒ¨ â†’ ì™¸ë¶€(PubMed)ë§Œ ì‚¬ìš©
    
    Flow:
    1. LLMìœ¼ë¡œ ì„ìƒ ë§¥ë½ ë¶„ì„
    2. ë‚´ë¶€ RAG ê²€ìƒ‰
    3. í’ˆì§ˆ í‰ê°€ (>= 1ê°œ?)
    4. ë‚´ë¶€ ìˆìŒ â†’ LLM ê²€ì¦
       - í†µê³¼ â†’ ë‚´ë¶€ + ì™¸ë¶€ (í•˜ì´ë¸Œë¦¬ë“œ)
       - ì‹¤íŒ¨ â†’ ì™¸ë¶€ë§Œ
    5. ë‚´ë¶€ ì—†ìŒ â†’ ë°”ë¡œ ì™¸ë¶€ë§Œ
    """
    patient = state["patient_case"]
    similar_cases = state.get("similar_cases", [])
    structured_chart = state.get("structured_chart", {})
    
    print(f"  [Evidence Agent] Patient diagnosis: {patient.get('diagnosis')}")
    print(f"  [Evidence Agent] Similar cases provided: {len(similar_cases)}")
    
    # 1. LLMìœ¼ë¡œ ì„ìƒ ë§¥ë½ ë¶„ì„
    print(f"  [Step 1/4] Analyzing clinical context with LLM...")
    clinical_analysis = analyze_clinical_context_with_llm(patient, structured_chart)
    
    # 2. ë‚´ë¶€ ê·¼ê±° ìˆ˜ì§‘ (ìœ ì‚¬ë„ í•„í„°ë§ ì ìš©)
    print(f"  [Step 2/4] Searching internal evidence...")
    query = generate_search_query_with_llm(patient, clinical_analysis)
    internal_results = []
    
    # queryëŠ” í•­ìƒ ìœ íš¨í•œ ë¬¸ìì—´ (ê¸°ë³¸ ì¿¼ë¦¬ í¬í•¨)
    if similar_cases:
        # ìœ ì‚¬ë„ >= thresholdì¸ ì¼€ì´ìŠ¤ë§Œ ì‚¬ìš©
        internal_results = [
            {
                "content": c.get("text", ""),
                "score": c.get("similarity", 0),
                "source": "internal",
                "case_id": c.get("id"),
                "status": c.get("status")
            }
            for c in similar_cases[:3]
            if c.get("similarity", 0) >= similarity_threshold
        ]
    elif rag_retriever:
        raw_results = search_internal_rag(query, rag_retriever, top_k=3)
        internal_results = [r for r in raw_results if r.get("score", 0) >= similarity_threshold]
    
    print(f"  [Internal] Found {len(internal_results)} cases above threshold {similarity_threshold}")
    
    # 3. í’ˆì§ˆ í‰ê°€
    print(f"  [Step 3/4] Evaluating quality...")
    quality = evaluate_internal_quality(internal_results, threshold=similarity_threshold)
    
    external_results = []
    retrieval_mode = ""
    final_internal = []
    validation_result = None
    
    if not quality["is_sufficient"]:
        # Case 1: ë‚´ë¶€ ì—†ìŒ (0ê°œ) â†’ ë°”ë¡œ ì™¸ë¶€ë§Œ ì‚¬ìš©
        print(f"  [CRAG] Internal insufficient ({quality['reason']}) â†’ EXTERNAL ONLY")
        retrieval_mode = "external_only"
        final_internal = []
        
        # PubMed ê²€ìƒ‰ (í•­ìƒ ìœ íš¨í•œ ì¿¼ë¦¬ ë°˜í™˜)
        pubmed_query = generate_pubmed_query_with_llm(patient, clinical_analysis)
        external_results = search_pubmed(pubmed_query, max_results=5)
        print(f"  [External] Found {len(external_results)} PubMed articles")
    
    else:
        # Case 2: ë‚´ë¶€ ìˆìŒ (>= 1ê°œ) â†’ LLM ê²€ì¦ ì§„í–‰
        print(f"  [Step 4/4] Internal found ({quality['reason']}) â†’ LLM validation...")
        validation_result = validate_internal_evidence_with_llm(internal_results, patient)
        
        if validation_result["is_valid"]:
            # ê²€ì¦ í†µê³¼ â†’ ë‚´ë¶€ + ì™¸ë¶€ ëª¨ë‘ ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ)
            print(f"  [LLM Validation] PASSED (confidence: {validation_result.get('confidence', 0):.2f})")
            print(f"  [LLM Validation] Reason: {validation_result.get('reason', 'N/A')}")
            print(f"  [CRAG] Internal validated â†’ HYBRID (internal + external)")
            retrieval_mode = "hybrid"
            final_internal = validation_result.get("filtered_results", [])
            
            # ì™¸ë¶€ë„ ê²€ìƒ‰ (í•­ìƒ ìœ íš¨í•œ ì¿¼ë¦¬ ë°˜í™˜)
            pubmed_query = generate_pubmed_query_with_llm(patient, clinical_analysis)
            external_results = search_pubmed(pubmed_query, max_results=5)
            print(f"  [External] Found {len(external_results)} PubMed articles")
        else:
            # ê²€ì¦ ì‹¤íŒ¨ â†’ ì™¸ë¶€ë§Œ ì‚¬ìš©
            print(f"  [LLM Validation] FAILED (confidence: {validation_result.get('confidence', 0):.2f})")
            print(f"  [LLM Validation] Reason: {validation_result.get('reason', 'N/A')}")
            print(f"  [CRAG] Internal not useful for critique â†’ EXTERNAL ONLY")
            retrieval_mode = "external_only_after_validation"
            final_internal = []
            
            # PubMed ê²€ìƒ‰ (í•­ìƒ ìœ íš¨í•œ ì¿¼ë¦¬ ë°˜í™˜)
            pubmed_query = generate_pubmed_query_with_llm(patient, clinical_analysis)
            external_results = search_pubmed(pubmed_query, max_results=5)
            print(f"  [External] Found {len(external_results)} PubMed articles")
    
    # 5. ê²°ê³¼ ë°˜í™˜
    evidence = {
        "retrieval_mode": retrieval_mode,
        "similarity_threshold": similarity_threshold,
        "quality_evaluation": quality,
        "validation_result": validation_result,
        "clinical_analysis": clinical_analysis,
        "internal": {
            "results": final_internal,
            "count": len(final_internal)
        },
        "external": {
            "results": external_results,
            "count": len(external_results)
        },
        "total_sources": len(final_internal) + len(external_results)
    }
    
    return {"evidence": evidence}


# ---------------------------------------------------------------------------
# 5. Evidence Agent 2ì°¨ (ë¹„íŒ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰)
# ---------------------------------------------------------------------------

def generate_critique_based_query(patient: Dict, preliminary_issues: List[Dict]) -> str:
    """
    ë¹„íŒ ë‚´ìš© ê¸°ë°˜ PubMed ì¿¼ë¦¬ ìƒì„±
    
    Args:
        patient: í™˜ì ì •ë³´
        preliminary_issues: Diagnosis/Treatment Agentì—ì„œ ë„ì¶œëœ ì´ˆê¸° ì´ìŠˆ
    
    Returns:
        str: ë¹„íŒ ë‚´ìš©ì— ë§ëŠ” íƒ€ê²Ÿ ê²€ìƒ‰ ì¿¼ë¦¬
    """
    diagnosis = patient.get("diagnosis", "Unknown")
    
    # ê¸°ë³¸ ì¿¼ë¦¬
    default_query = f"{diagnosis} complication management guideline"
    
    if not preliminary_issues:
        return default_query
    
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ì´ìŠˆ ìš”ì•½
        issues_text = "\n".join([
            f"- [{issue.get('category', 'unknown')}] {issue.get('issue', '')}"
            for issue in preliminary_issues[:5]
        ])
        
        prompt = f"""Generate ONE PubMed query to find evidence for these clinical issues.

Patient Diagnosis: {diagnosis}

Issues Found:
{issues_text}

Goal: Find literature about these SPECIFIC issues (not general guidelines)

Rules:
1. Focus on the MOST CRITICAL issue
2. Include diagnosis + specific issue keywords
3. Add: "missed diagnosis" / "delayed diagnosis" / "complication" / "prevention" as relevant
4. 5-8 keywords total
5. Return ONLY the query string

Example:
Issues: "PE diagnosis delayed", "D-dimer not ordered"
Query: pulmonary embolism missed diagnosis pneumonia D-dimer diagnostic delay"""

        response = client.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
            max_tokens=100,
            temperature=0,
            messages=[{"role": "user", "content": prompt}],
            timeout=30
        )
        
        query = response.choices[0].message.content.strip().strip('"').strip("'")
        
        if not query or len(query.strip()) == 0:
            return default_query
        
        print(f"  [2nd Pass Query] Generated: {query}")
        return query
        
    except Exception as e:
        print(f"  [ERROR] Critique-based query generation failed: {e}")
        return default_query


def run_evidence_agent_2nd_pass(state: Dict, rag_retriever=None) -> Dict:
    """
    2ì°¨ Evidence ê²€ìƒ‰ (CRAG: ë‚´ë¶€ RAG + PubMed, ë¹„íŒ ê¸°ë°˜)

    Diagnosis/Treatment Agentì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ë¹„íŒ ë‚´ìš©ì— ë§ëŠ” íƒ€ê²Ÿ ê²€ìƒ‰ ìˆ˜í–‰ (CRAG ì „ëµ)

    Args:
        state: AgentState
        rag_retriever: ë‚´ë¶€ RAG ê²€ìƒ‰ê¸° (1ì°¨ì™€ ë™ì¼ ì¸ìŠ¤í„´ìŠ¤)
    """
    patient = state.get("patient_case", {})
    existing_evidence = state.get("evidence", {})

    # â”€â”€ ì´ˆê¸° ì´ìŠˆ ìˆ˜ì§‘ (Diagnosis + Treatment Agent ê²°ê³¼) â”€â”€
    preliminary_issues = []

    diagnosis_analysis = state.get("diagnosis_analysis", {})
    if diagnosis_analysis:
        for issue in diagnosis_analysis.get("issues", []):
            preliminary_issues.append({
                "category": "diagnosis",
                "issue": issue.get("issue", "") if isinstance(issue, dict) else str(issue),
                "severity": issue.get("severity", "medium") if isinstance(issue, dict) else "medium"
            })
        for missed in diagnosis_analysis.get("missed_diagnoses", []):
            preliminary_issues.append({
                "category": "missed_diagnosis",
                "issue": missed.get("condition", "") if isinstance(missed, dict) else str(missed),
                "severity": "critical"
            })

    treatment_analysis = state.get("treatment_analysis", {})
    if treatment_analysis:
        for issue in treatment_analysis.get("medication_issues", []) or []:
            text = issue if isinstance(issue, str) else issue.get("issue", str(issue))
            preliminary_issues.append({
                "category": "treatment_medication",
                "issue": text,
                "severity": "medium"
            })
        for issue in treatment_analysis.get("timing_issues", []) or []:
            text = issue if isinstance(issue, str) else issue.get("issue", str(issue))
            preliminary_issues.append({
                "category": "treatment_timing",
                "issue": text,
                "severity": "medium"
            })

    # ì´ìŠˆê°€ ì—†ìœ¼ë©´ 2ì°¨ ê²€ìƒ‰ ìŠ¤í‚µ
    if not preliminary_issues:
        print("  [2nd Pass] No preliminary issues found, skipping")
        return {}

    # Critical ì´ìŠˆ ìš°ì„  ì •ë ¬
    preliminary_issues.sort(key=lambda x: 0 if x.get("severity") == "critical" else 1)

    print(f"  [2nd Pass] Found {len(preliminary_issues)} preliminary issues")
    print(f"  [2nd Pass] Top issues: {[i.get('issue', '')[:50] for i in preliminary_issues[:3]]}")

    # ë¹„íŒ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±
    critique_query = generate_critique_based_query(patient, preliminary_issues)

    # === CRAG 1ë‹¨ê³„: ë‚´ë¶€ RAG ê²€ìƒ‰ (ë¹„íŒ ê¸°ë°˜ ì¿¼ë¦¬) ===
    critique_internal_results: List[Dict] = []
    if rag_retriever:
        try:
            raw_results = search_internal_rag(critique_query, rag_retriever, top_k=3)
            critique_internal_results = [
                r for r in raw_results
                if r.get("score", 0) >= SIMILARITY_THRESHOLD
            ]
            print(f"  [2nd Pass CRAG] Internal: {len(critique_internal_results)} cases above threshold {SIMILARITY_THRESHOLD}")
        except Exception as e:
            print(f"  [2nd Pass CRAG] Internal RAG search failed: {e}")

    # === CRAG 2ë‹¨ê³„: PubMed ê²€ìƒ‰ ===
    critique_results = search_pubmed(critique_query, max_results=5)
    print(f"  [2nd Pass CRAG] External: {len(critique_results)} targeted PubMed articles")

    # â”€â”€ ê¸°ì¡´ evidenceì— 2ì°¨ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (ì›ë³¸ mutation ë°©ì§€) â”€â”€
    updated_evidence = {
        k: v for k, v in existing_evidence.items()
        if k not in ("internal", "external", "total_sources", "critique_based")
    }

    # 2ì°¨ ê²€ìƒ‰ ê²°ê³¼ ì„¹ì…˜ ì¶”ê°€
    updated_evidence["critique_based"] = {
        "query": critique_query,
        "results": critique_results,
        "count": len(critique_results),
        "internal_results": critique_internal_results,
        "internal_count": len(critique_internal_results),
        "preliminary_issues": preliminary_issues[:5]
    }

    # ì™¸ë¶€ ê²°ê³¼ ë³‘í•© (ìƒˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±, ì¤‘ë³µ PMID ì œê±°)
    prev_external = existing_evidence.get("external", {}).get("results", [])
    prev_pmids = {r.get("pmid") for r in prev_external}
    new_external = [r for r in critique_results if r.get("pmid") not in prev_pmids]
    merged_external = prev_external + new_external
    updated_evidence["external"] = {
        "results": merged_external,
        "count": len(merged_external),
    }

    # ë‚´ë¶€ ê²°ê³¼ ë³‘í•© (ìƒˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±, ì¤‘ë³µ case_id ì œê±°)
    prev_internal = existing_evidence.get("internal", {}).get("results", [])
    prev_case_ids = {r.get("case_id") for r in prev_internal if r.get("case_id")}
    new_internal = [r for r in critique_internal_results if r.get("case_id") not in prev_case_ids]
    merged_internal = prev_internal + new_internal
    updated_evidence["internal"] = {
        "results": merged_internal,
        "count": len(merged_internal),
    }

    updated_evidence["total_sources"] = len(merged_internal) + len(merged_external)

    return {"evidence": updated_evidence}